{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Finding Lane Lines on the Road** \n",
    "***\n",
    "This project provides basic algorithm to detect a lane on a road. \n",
    "First the Helper Functions are declared, which consists of the deepest implementation level.\n",
    "As an abstraction, a pipeline function is implemented that can just be called with one parameter, your image.\n",
    "The return value is your image with the detected lanes on it.\n",
    "\n",
    "To see the developed algorithm in action, you can easily execute the apply it on several test images and even videos.\n",
    "\n",
    "Have fun!\n",
    "E-Mail: alextreib94@gmail.com\n",
    "\n",
    "---\n",
    "\n",
    "**Note: If you encounter a import error or anything like that, make sure you have loaded all previous module. (Just click Run). If, at any point, you encounter frozen display windows or other confounding issues, you can always start again with a clean slate by going to the \"Kernel\" menu above and selecting \"Restart & Clear Output**\n",
    "\n",
    "Make sure you have all prerequisites:\n",
    "https://github.com/udacity/CarND-Term1-Starter-Kit\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some helper functions that help building up the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "###Parameters###\n",
    "#Region of interest\n",
    "left_bottom = [110, 540]\n",
    "right_bottom = [960, 520]\n",
    "apex = [480, 310]\n",
    "vertices=np.array([left_bottom,right_bottom,apex])\n",
    "\n",
    "#Gaussian blur\n",
    "kernel=5\n",
    "\n",
    "#Canny\n",
    "low_threshold=50 \n",
    "high_threshold=150\n",
    "\n",
    "#Hough\n",
    "rho = 1\n",
    "theta = np.pi/180\n",
    "hough_threshold = 1\n",
    "min_line_len = 3\n",
    "max_line_gap = 1\n",
    "\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    (assuming your grayscaled image is called 'gray')\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, np.int32([vertices]), ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    This function draws the lines with an inplace drawing.\n",
    "    Here, the lines and the mainline are drawn.\n",
    "    \"\"\"   \n",
    "    \n",
    "    left_edge=[left_bottom,apex]\n",
    "    right_edge=[right_bottom,apex]\n",
    "    \n",
    "    left_lines=[]\n",
    "    right_lines=[]\n",
    "    left_points=[]\n",
    "    right_points=[]\n",
    "    \n",
    "    #Separating the line into left and right lines\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            #Only for formatting\n",
    "            point_line=[(x1,y1),(x2,y2)]\n",
    "            element_line=[x1,y1,x2,y2]\n",
    "            \n",
    "            #What is closer?\n",
    "            if(linediff(left_edge,point_line)<linediff(right_edge,point_line)):\n",
    "            #Closer to left\n",
    "                left_lines.append([element_line])\n",
    "                left_points.append([x1,y1])\n",
    "                left_points.append([x2,y2])\n",
    "            else:\n",
    "            #Closer to right\n",
    "                right_lines.append([element_line])\n",
    "                right_points.append([x1,y1])\n",
    "                right_points.append([x2,y2])\n",
    "    \n",
    "    #Drawing the mainLanes in red\n",
    "    draw_mainLane(img,right_points)\n",
    "    draw_mainLane(img,left_points)\n",
    "    \n",
    "    #Drawing the little lines (green for left lane, blue for right lane)\n",
    "    for line in left_lines:        \n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), [0, 255, 0], thickness)\n",
    "           \n",
    "    for line in right_lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), [0, 0, 255], thickness)\n",
    "\n",
    "def draw_mainLane(img,points):\n",
    "    \"\"\"\n",
    "    This function draws the main lane with the given points.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    #Calculate the length of the vector\n",
    "    x_values=(np.array(points))[:,0]\n",
    "    y_values=(np.array(points))[:,1]\n",
    "    x_values.sort()\n",
    "    y_values.sort()\n",
    "    \n",
    "    #Get last 10&\n",
    "    percent=0.2\n",
    "    highest_x=x_values[-int(x_values.size*percent):].mean()\n",
    "    lowest_x=x_values[:int(x_values.size*percent)].mean()\n",
    "    highest_y=y_values[-int(y_values.size*percent):].mean()\n",
    "    lowest_y=y_values[:int(y_values.size*percent)].mean()\n",
    "    \n",
    "    #Calculate the distance between the two points \n",
    "    dist=cv2.norm((highest_x,highest_y), (lowest_x,lowest_y))\n",
    "    \n",
    "    [vx,vy,x0,y0] = cv2.fitLine(np.array(points, dtype=np.int32), cv2.DIST_L2,0,0.01,0.01)\n",
    "    \n",
    "    #m is the length of the vector\n",
    "    m=dist*0.5\n",
    "    x1=int(x0-m*vx)\n",
    "    y1=int(y0-m*vy)\n",
    "    x2=int(x0+m*vx)\n",
    "    y2=int(y0+m*vy)\n",
    "    \n",
    "    #Finally, draw the line\n",
    "    cv2.line(img, (x1, y1), (x2, y2), [255, 0, 0], 30)\n",
    "            \n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + γ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)\n",
    "\n",
    "\n",
    "def linediff(firstline, secondline):\n",
    "    \"\"\"\n",
    "    Calculates the minimum distance between two lines (calculated with perpendicular vector)\n",
    "    input parameter:\n",
    "    firstline - line that contains the x1,y1,x2,y2 for one line\n",
    "    secondline -line that contains the x1,y1,x2,y2 for second line\n",
    "    \n",
    "    returns - shortest distance between lines\n",
    "    \"\"\"\n",
    "\n",
    "    #Calculate the cross product to a perpendicular vector \n",
    "    (Fx1,Fy1),(Fx2,Fy2) = firstline\n",
    "    (Sx1,Sy1),(Sx2,Sy2) = secondline\n",
    "    Fdx,Fdy = Fx2-Fx1,Fy2-Fy1\n",
    "    Sdx,Sdy = Sx2-Sx1,Sy2-Sy1\n",
    "    \n",
    "    perpen_vec_dx,perpen_vec_dy = (Fdy - Sdy, Sdx-Fdx)\n",
    "\n",
    "    #Perpen_vecp_normalized = perpen_vec / distance of common perp\n",
    "    perpen_vec_length = math.hypot(perpen_vec_dx,perpen_vec_dy)\n",
    "    \n",
    "    perpen_vec_normalized_dx = perpen_vec_dx/float(perpen_vec_length)\n",
    "    perpen_vec_normalized_dy = perpen_vec_dy/float(perpen_vec_length)\n",
    "\n",
    "    #step3: length of (pointonline1-pointonline2 dotprod normalized_perp).\n",
    "    short_vec_dx = (Fx1-Sx1)*perpen_vec_normalized_dx\n",
    "    short_vec_dy = (Fy1-Sy1)*perpen_vec_normalized_dy\n",
    "\n",
    "    minimum_distance = math.hypot(short_vec_dx,short_vec_dy)\n",
    "    \n",
    "    return minimum_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane Finding Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build pipeline function that contains that overall dataflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(origin_img):\n",
    "    #Main functionality\n",
    "    gray_img=grayscale(origin_img)\n",
    "    blurred_img=gaussian_blur(gray_img, kernel)\n",
    "    masked_edges =canny(blurred_img, low_threshold, high_threshold)\n",
    "    filtered_masked_edges=region_of_interest(masked_edges, vertices)\n",
    "    line_img=hough_lines(filtered_masked_edges, rho, theta, hough_threshold, min_line_len, max_line_gap)\n",
    "\n",
    "    output_img = weighted_img(line_img, origin_img)    \n",
    "    return output_img    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building tests images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the pipeline algorithm will be applied to all the provided test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "test_images=os.listdir(\"test/images/\")\n",
    "output_directory='results/images/'\n",
    "\n",
    "try:\n",
    "    os.stat(output_directory)\n",
    "except:\n",
    "    os.mkdir(output_directory)       \n",
    "\n",
    "#Going through every test_image\n",
    "for file_name in test_images:\n",
    "    img = cv2.imread('test/images/'+file_name)\n",
    "    img=pipeline(img)\n",
    "    cv2.imwrite(output_directory+file_name, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the pipeline on test videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code snippet, the pipeline will be tested on test/videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video results/videos/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video results/videos/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▋| 221/222 [00:03<00:00, 66.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: results/videos/solidWhiteRight.mp4 \n",
      "\n",
      "Wall time: 3.73 s\n",
      "[MoviePy] >>>> Building video results/videos/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video results/videos/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 681/682 [00:10<00:00, 63.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: results/videos/solidYellowLeft.mp4 \n",
      "\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "def pipeline_handle(image):\n",
    "    return pipeline(image)\n",
    "\n",
    "test_videos=os.listdir(\"test/videos/\")\n",
    "\n",
    "for file_name in test_videos:\n",
    "    video_fileName = 'test/videos/'+file_name\n",
    "    fileClip = VideoFileClip(video_fileName)\n",
    "    clip = fileClip.fl_image(pipeline_handle)\n",
    "\n",
    "    %time clip.write_videofile('results/videos/'+file_name, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can your videos in the directory results/videos.\n",
    "Enjoy watching!\n",
    "\n",
    "--\n",
    "\n",
    "The End"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
